<!DOCTYPE html><html><head>
      <title>result_analysis</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/javascript">
          window.MathJax = ({"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"options":{},"loader":{}});
        </script>
        <script type="text/javascript" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="result-analysis">result analysis </h1>
<h2 id="1">1 </h2>
<h3 id="关于-unlearn_acc-数据的分析">关于 <code>unlearn_acc</code> 数据的分析： </h3>
<ol>
<li>
<p><strong>机器学习方法的表现差异</strong>:</p>
<ul>
<li>不同的机器学习方法在 <code>unlearn_acc</code> 的多个指标上表现出显著差异。例如，一些方法在 <code>retain</code> 指标上表现优异，而另一些方法在 <code>forget</code> 指标上表现较好。这表明不同的unlearning方法可能适合不同的应用场景。</li>
</ul>
</li>
<li>
<p><strong>模型和数据集的影响</strong>:</p>
<ul>
<li>不同的数据集和模型组合对同一方法的性能有显著影响。例如，同样的方法在 CIFAR-10 和 CIFAR-100 数据集上的表现可能会有所不同。这表明数据集和模型选择对于unlearning的效果至关重要。</li>
</ul>
</li>
<li>
<p><strong>整体性能的提升</strong>:</p>
<ul>
<li>从 <code>ft_before</code> 到 <code>ft_after</code>，大多数方法的表现都有所提升，特别是在 <code>retain</code> 和 <code>val</code> 指标上。这表明进行了某种改进（可能是算法调整或数据预处理），提升了模型的整体性能。</li>
</ul>
</li>
<li>
<p><strong>特定方法的改进效果</strong>:</p>
<ul>
<li>一些特定的方法在改进后（<code>ft_after</code>）表现出明显的改进，尤其是在关键指标（如 <code>test</code> 和 <code>forget</code>）上。这表明这些方法在改进过程中受益最大，可能因为改进更好地适应了特定的数据或任务。</li>
</ul>
</li>
</ol>
<h3 id="关于-mia-数据的分析">关于 <code>mia</code> 数据的分析： </h3>
<ol>
<li>
<p><strong>Membership Inference Attack（MIA） 的表现</strong>:</p>
<ul>
<li>MIA 的表现可以用来评估模型的隐私风险。通过分析 <code>ft_before</code> 和 <code>ft_after</code> 在 MIA 指标上的变化，我们可以看到某些方法在降低隐私泄露风险方面有所改进。这对于保护数据隐私和安全至关重要。</li>
</ul>
</li>
<li>
<p><strong>不同方法的隐私保护能力</strong>:</p>
<ul>
<li>不同的unlearning方法在MIA指标上的表现差异显著。一些方法在 <code>ft_after</code> 阶段显著降低了MIA的成功率，表明这些方法在隐私保护方面更为有效。这对选择合适的unlearning方法以提高模型的隐私性有指导意义。</li>
</ul>
</li>
<li>
<p><strong>指标之间的平衡</strong>:</p>
<ul>
<li>柱状图显示了模型在保持精度和降低MIA成功率之间的权衡。某些方法可能在精度上有所妥协以降低隐私泄露的风险，而其他方法则可能在保持高精度的同时提供有限的隐私保护。</li>
</ul>
</li>
</ol>
<h3 id="总结">总结: </h3>
<p>从以上分析可以看出，<code>ft_before</code> 和 <code>ft_after</code> 阶段的大多数方法都表现出明显的改进，尤其是在性能和隐私保护方面。不同的数据集和模型组合对方法的影响显著，选择合适的方法和配置对实现预期效果至关重要。此外，MIA分析提供了关于模型隐私风险的重要信息，帮助理解和减少数据泄露的潜在风险。</p>
<h2 id="2">2 </h2>
<p>基于以上实验数据的可视化分析，可以得到以下几点结论：</p>
<ol>
<li>
<p><strong>性能变化的整体趋势</strong>:</p>
<ul>
<li>从并行坐标图和小提琴图可以看出，大多数方法在 <code>ft_after</code> 阶段比 <code>ft_before</code> 有更好的性能。这表明进行了某种改进，提升了整体模型的性能。</li>
</ul>
</li>
<li>
<p><strong>不同方法的稳定性和分布</strong>:</p>
<ul>
<li>通过小提琴图，可以观察到 <code>ft_before</code> 和 <code>ft_after</code> 阶段的不同方法在数据分布上的差异。某些方法在改进后（<code>ft_after</code>）有更集中的分布，这表明改进后的方法可能更加稳定，减少了性能的波动。</li>
</ul>
</li>
<li>
<p><strong>方法间的性能差异</strong>:</p>
<ul>
<li>从散点矩阵图可以看出，各种方法在不同指标上的表现差异。有些方法在某些特定的指标上明显优于其他方法，这有助于识别出最适合某一类任务的最佳方法。</li>
</ul>
</li>
<li>
<p><strong>三维空间中的数据聚类</strong>:</p>
<ul>
<li>通过三维散点图，我们能够看到在 <code>retain</code>、<code>forget</code> 和 <code>val</code> 这些关键指标上的数据分布情况。我们可以识别出哪些方法在这些指标上表现更为出色或相对均衡。</li>
</ul>
</li>
<li>
<p><strong>数据点间的相似性和关系</strong>:</p>
<ul>
<li>网络图展示了 <code>ft_before</code> 和 <code>ft_after</code> 数据点之间的相似性。我们可以看到，许多数据点在改进后（<code>ft_after</code>）趋于更接近，表明改进可能使得模型的不同部分更加一致或协调。</li>
</ul>
</li>
<li>
<p><strong>特定方法的改进效果</strong>:</p>
<ul>
<li>在针对特定方法的图中，可以看出某些方法在 <code>ft_after</code> 的表现明显改善，尤其是在特定的指标上。这有助于识别出哪些方法在改进过程中收益最大，哪些指标受到了最大影响。</li>
</ul>
</li>
</ol>
<h3 id="总结-1">总结: </h3>
<p>总体而言，这些图表展示了在 <code>ft_before</code> 和 <code>ft_after</code> 阶段不同方法的性能变化和分布情况。我们观察到，在大多数情况下，<code>ft_after</code> 阶段的性能优于 <code>ft_before</code>，这表明改进对模型的整体性能有正面影响。此外，不同方法在不同指标上的表现差异也表明，特定任务可能需要特定的方法来获得最佳效果。这些结论可以帮助进一步优化模型和方法，针对具体的应用场景进行调整和改进。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code></code></pre><h1 id="unlearn-acc">unlearn acc </h1>
<h2 id="by-datasetmodel">by (dataset,model) </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> pandas <span class="token keyword keyword-as">as</span> pd
<span class="token keyword keyword-import">import</span> json
<span class="token keyword keyword-import">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword keyword-as">as</span> plt
<span class="token keyword keyword-import">import</span> os
<span class="token keyword keyword-import">import</span> zipfile

<span class="token comment"># # Step 1: Unzip the files</span>
<span class="token comment"># ft_before_extract_path = '/mnt/data/ft_before_corrected'</span>
<span class="token comment"># ft_after_extract_path = '/mnt/data/ft_after_corrected'</span>

<span class="token comment"># with zipfile.ZipFile('/mnt/data/ft_before.zip', 'r') as zip_ref:</span>
<span class="token comment">#     zip_ref.extractall(ft_before_extract_path)</span>

<span class="token comment"># with zipfile.ZipFile('/mnt/data/ft_after.zip', 'r') as zip_ref:</span>
<span class="token comment">#     zip_ref.extractall(ft_after_extract_path)</span>

<span class="token comment"># Step 2: Define the paths for 'unlearn_acc.csv' files</span>
<span class="token comment"># ft_before_correct_path = os.path.join(ft_before_extract_path, 'ft_before', 'unlearn_acc.csv')</span>
<span class="token comment"># ft_after_correct_path = os.path.join(ft_after_extract_path, 'ft_after', 'unlearn_acc.csv')</span>

ft_before_correct_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_before'</span><span class="token punctuation">,</span> <span class="token string">'unlearn_acc.csv'</span><span class="token punctuation">)</span>
ft_after_correct_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_after'</span><span class="token punctuation">,</span> <span class="token string">'unlearn_acc.csv'</span><span class="token punctuation">)</span>

<span class="token comment"># Step 3: Load the CSV files into DataFrames</span>
unlearn_acc_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>ft_before_correct_path<span class="token punctuation">)</span>
unlearn_acc_after_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>ft_after_correct_path<span class="token punctuation">)</span>

<span class="token comment"># Step 4: Correct the JSON format in the DataFrames</span>
<span class="token keyword keyword-def">def</span> <span class="token function">correct_json_format</span><span class="token punctuation">(</span>json_str<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-return">return</span> json_str<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">'"'</span><span class="token punctuation">)</span>

unlearn_acc_df_corrected <span class="token operator">=</span> unlearn_acc_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
unlearn_acc_after_df_corrected <span class="token operator">=</span> unlearn_acc_after_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> unlearn_acc_df_corrected<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    unlearn_acc_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> unlearn_acc_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>
    unlearn_acc_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> unlearn_acc_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>

<span class="token comment"># Step 5: Filter out rows with non-dictionary JSON data</span>
<span class="token keyword keyword-def">def</span> <span class="token function">is_valid_json</span><span class="token punctuation">(</span>val<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-try">try</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>val<span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-except">except</span> <span class="token punctuation">(</span>json<span class="token punctuation">.</span>JSONDecodeError<span class="token punctuation">,</span> TypeError<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> <span class="token boolean">False</span>

filtered_df <span class="token operator">=</span> unlearn_acc_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
filtered_after_df <span class="token operator">=</span> unlearn_acc_after_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> col <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    filtered_df <span class="token operator">=</span> filtered_df<span class="token punctuation">[</span>filtered_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>
    filtered_after_df <span class="token operator">=</span> filtered_after_df<span class="token punctuation">[</span>filtered_after_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token comment"># Step 6: Extract the valid data keys</span>
first_valid_data_cell <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>filtered_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
valid_data_keys <span class="token operator">=</span> first_valid_data_cell<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Step 7: Function to plot 9-grid comparison for a given dataset, handling None values</span>
<span class="token keyword keyword-def">def</span> <span class="token function">plot_comparison</span><span class="token punctuation">(</span>dataset_column<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    axes <span class="token operator">=</span> axes<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-for">for</span> idx<span class="token punctuation">,</span> key <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>valid_data_keys<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax <span class="token operator">=</span> axes<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        before_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        after_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            method <span class="token operator">=</span> row<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            before_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset_column<span class="token punctuation">]</span><span class="token punctuation">)</span>
            before_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>before_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Use 0 for None values</span>
            labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>method<span class="token punctuation">)</span>

            after_row <span class="token operator">=</span> filtered_after_df<span class="token punctuation">[</span>filtered_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
            <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> after_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
                after_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>after_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset_column<span class="token punctuation">]</span><span class="token punctuation">)</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>after_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Use 0 for None values</span>
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        x <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        width <span class="token operator">=</span> <span class="token number">0.35</span>

        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>x<span class="token punctuation">,</span> before_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Before'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">,</span> after_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'After'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>

        ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Method'</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width<span class="token operator">/</span><span class="token number">2</span> <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>
    fig<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Performance Comparison for </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_column<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figtext<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token string">'Note: "Before" represents the performance before changes; "After" represents the performance after changes.'</span><span class="token punctuation">,</span> ha<span class="token operator">=</span><span class="token string">'center'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>rect<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.95</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Step 8: List of datasets to plot and plotting for each dataset</span>
datasets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'cifar10_resnet18'</span><span class="token punctuation">,</span> <span class="token string">'cifar10_vgg16'</span><span class="token punctuation">,</span> <span class="token string">'cifar100_resnet18'</span><span class="token punctuation">,</span> 
            <span class="token string">'cifar100_vgg16'</span><span class="token punctuation">,</span> <span class="token string">'tinyimg_resnet18'</span><span class="token punctuation">,</span> <span class="token string">'tinyimg_vgg16'</span><span class="token punctuation">,</span> 
            <span class="token string">'fmnist_resnet18'</span><span class="token punctuation">,</span> <span class="token string">'fmnist_vgg16'</span><span class="token punctuation">]</span>

<span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> datasets<span class="token punctuation">:</span>
    plot_comparison<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>

</code></pre><pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_1.png" alt="png"></p>
<pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_3.png" alt="png"></p>
<pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_5.png" alt="png"></p>
<pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_7.png" alt="png"></p>
<pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_9.png" alt="png"></p>
<pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_11.png" alt="png"></p>
<pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_13.png" alt="png"></p>
<pre class="language-text">/tmp/ipykernel_240749/3291352032.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_8_15.png" alt="png"></p>
<h2 id="by-mu-method">by MU method </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Function to plot comparison for each machine unlearning method</span>
<span class="token keyword keyword-def">def</span> <span class="token function">plot_method_comparison</span><span class="token punctuation">(</span>method_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    axes <span class="token operator">=</span> axes<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-for">for</span> idx<span class="token punctuation">,</span> key <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>valid_data_keys<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax <span class="token operator">=</span> axes<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        before_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        after_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            before_row <span class="token operator">=</span> filtered_df<span class="token punctuation">[</span>filtered_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method_name<span class="token punctuation">]</span>
            after_row <span class="token operator">=</span> filtered_after_df<span class="token punctuation">[</span>filtered_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method_name<span class="token punctuation">]</span>

            <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> before_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
                before_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>before_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">)</span>
                before_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>before_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                before_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

            <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> after_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
                after_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>after_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">)</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>after_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

            labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>

        x <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        width <span class="token operator">=</span> <span class="token number">0.35</span>

        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>x<span class="token punctuation">,</span> before_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Before'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">,</span> after_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'After'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>

        ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Dataset + Model'</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width<span class="token operator">/</span><span class="token number">2</span> <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

    fig<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Performance Comparison for Method: </span><span class="token interpolation"><span class="token punctuation">{</span>method_name<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figtext<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token string">'Note: "Before" represents the performance before changes; "After" represents the performance after changes.'</span><span class="token punctuation">,</span> ha<span class="token operator">=</span><span class="token string">'center'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>rect<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.95</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Plotting for each machine unlearning method in unlearn_acc</span>
methods <span class="token operator">=</span> filtered_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> methods<span class="token punctuation">:</span>
    plot_method_comparison<span class="token punctuation">(</span>method<span class="token punctuation">)</span>


</code></pre><p><img src="result_analysis_files/result_analysis_10_0.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_10_1.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_10_2.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_10_3.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_10_4.png" alt="png"></p>
<h1 id="mia">mia </h1>
<h2 id="by-datasetmodel-1">by (dataset,model) </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> pandas <span class="token keyword keyword-as">as</span> pd
<span class="token keyword keyword-import">import</span> json
<span class="token keyword keyword-import">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword keyword-as">as</span> plt
<span class="token keyword keyword-import">import</span> os
<span class="token keyword keyword-import">import</span> zipfile

<span class="token comment"># # Step 1: Unzip the files</span>
<span class="token comment"># ft_before_extract_path = '/mnt/data/ft_before_corrected'</span>
<span class="token comment"># ft_after_extract_path = '/mnt/data/ft_after_corrected'</span>

<span class="token comment"># with zipfile.ZipFile('/mnt/data/ft_before.zip', 'r') as zip_ref:</span>
<span class="token comment">#     zip_ref.extractall(ft_before_extract_path)</span>

<span class="token comment"># with zipfile.ZipFile('/mnt/data/ft_after.zip', 'r') as zip_ref:</span>
<span class="token comment">#     zip_ref.extractall(ft_after_extract_path)</span>

<span class="token comment"># Load the 'mia_after.csv' files from both directories</span>
<span class="token comment"># mia_before_path = os.path.join(ft_before_extract_path, 'ft_before', 'mia_after.csv')</span>
<span class="token comment"># mia_after_path = os.path.join(ft_after_extract_path, 'ft_after', 'mia_after.csv')</span>
mia_before_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_before'</span><span class="token punctuation">,</span> <span class="token string">'mia_after.csv'</span><span class="token punctuation">)</span>
mia_after_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_after'</span><span class="token punctuation">,</span> <span class="token string">'mia_after.csv'</span><span class="token punctuation">)</span>

mia_before_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>mia_before_path<span class="token punctuation">)</span>
mia_after_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>mia_after_path<span class="token punctuation">)</span>

<span class="token comment"># Correct the JSON format in the DataFrames</span>
mia_before_df_corrected <span class="token operator">=</span> mia_before_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
mia_after_df_corrected <span class="token operator">=</span> mia_after_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> mia_before_df_corrected<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    mia_before_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> mia_before_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>
    mia_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> mia_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>

<span class="token comment"># Filter out rows with non-dictionary JSON data</span>
filtered_mia_before_df <span class="token operator">=</span> mia_before_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
filtered_mia_after_df <span class="token operator">=</span> mia_after_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> col <span class="token keyword keyword-in">in</span> filtered_mia_before_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    filtered_mia_before_df <span class="token operator">=</span> filtered_mia_before_df<span class="token punctuation">[</span>filtered_mia_before_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>
    filtered_mia_after_df <span class="token operator">=</span> filtered_mia_after_df<span class="token punctuation">[</span>filtered_mia_after_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token comment"># Extract the valid data keys for MIA analysis</span>
mia_first_valid_data_cell <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>filtered_mia_before_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
mia_valid_data_keys <span class="token operator">=</span> mia_first_valid_data_cell<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Function to plot 9-grid comparison for MIA data</span>
<span class="token keyword keyword-def">def</span> <span class="token function">plot_mia_comparison</span><span class="token punctuation">(</span>dataset_column<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    axes <span class="token operator">=</span> axes<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-for">for</span> idx<span class="token punctuation">,</span> key <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mia_valid_data_keys<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax <span class="token operator">=</span> axes<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        before_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        after_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row <span class="token keyword keyword-in">in</span> filtered_mia_before_df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            method <span class="token operator">=</span> row<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            before_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset_column<span class="token punctuation">]</span><span class="token punctuation">)</span>
            before_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>before_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>method<span class="token punctuation">)</span>

            after_row <span class="token operator">=</span> filtered_mia_after_df<span class="token punctuation">[</span>filtered_mia_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
            <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> after_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
                after_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>after_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset_column<span class="token punctuation">]</span><span class="token punctuation">)</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>after_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        x <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        width <span class="token operator">=</span> <span class="token number">0.35</span>

        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>x<span class="token punctuation">,</span> before_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Before'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">,</span> after_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'After'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>

        ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Method'</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width<span class="token operator">/</span><span class="token number">2</span> <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

    fig<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'MIA Performance Comparison for </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_column<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figtext<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token string">'Note: "Before" represents the performance before changes; "After" represents the performance after changes.'</span><span class="token punctuation">,</span> ha<span class="token operator">=</span><span class="token string">'center'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>rect<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.95</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Plotting for MIA data</span>
mia_datasets <span class="token operator">=</span> filtered_mia_before_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> mia_datasets<span class="token punctuation">:</span>
    plot_mia_comparison<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>


</code></pre><pre class="language-text">/tmp/ipykernel_247547/3618421346.py:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_13_1.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_13_2.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_13_3.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_13_4.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_13_5.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_13_6.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_13_7.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_13_8.png" alt="png"></p>
<h2 id="by-mu-method-1">by MU method </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Function to plot comparison for each machine unlearning method in MIA data</span>
<span class="token keyword keyword-def">def</span> <span class="token function">plot_mia_method_comparison</span><span class="token punctuation">(</span>method_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    axes <span class="token operator">=</span> axes<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-for">for</span> idx<span class="token punctuation">,</span> key <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mia_valid_data_keys<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax <span class="token operator">=</span> axes<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        before_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        after_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> filtered_mia_before_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            before_row <span class="token operator">=</span> filtered_mia_before_df<span class="token punctuation">[</span>filtered_mia_before_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method_name<span class="token punctuation">]</span>
            after_row <span class="token operator">=</span> filtered_mia_after_df<span class="token punctuation">[</span>filtered_mia_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method_name<span class="token punctuation">]</span>

            <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> before_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
                before_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>before_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">)</span>
                before_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>before_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                before_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

            <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> after_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
                after_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>after_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">)</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>after_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
                after_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

            labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>

        x <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        width <span class="token operator">=</span> <span class="token number">0.35</span>

        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>x<span class="token punctuation">,</span> before_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Before'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">,</span> after_values<span class="token punctuation">,</span> width<span class="token operator">=</span>width<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'After'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>

        ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Dataset + Model'</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">.</span>capitalize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token operator">+</span> width<span class="token operator">/</span><span class="token number">2</span> <span class="token keyword keyword-for">for</span> p <span class="token keyword keyword-in">in</span> x<span class="token punctuation">]</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

    fig<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'MIA Performance Comparison for Method: </span><span class="token interpolation"><span class="token punctuation">{</span>method_name<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figtext<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token string">'Note: "Before" represents the performance before changes; "After" represents the performance after changes.'</span><span class="token punctuation">,</span> ha<span class="token operator">=</span><span class="token string">'center'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>rect<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.95</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Plotting for each machine unlearning method in MIA data</span>
mia_methods <span class="token operator">=</span> filtered_mia_before_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> mia_methods<span class="token punctuation">:</span>
    plot_mia_method_comparison<span class="token punctuation">(</span>method<span class="token punctuation">)</span>

</code></pre><p><img src="result_analysis_files/result_analysis_15_0.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_15_1.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_15_2.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_15_3.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_15_4.png" alt="png"></p>
<h1 id="热力图">热力图 </h1>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Adjusting data handling for missing values</span>
<span class="token comment"># Initialize a dictionary to store aggregated results with default values</span>

aggregated_data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token comment"># Function to aggregate data for a given dataset column with default handling</span>
<span class="token keyword keyword-def">def</span> <span class="token function">aggregate_data_for_dataset</span><span class="token punctuation">(</span>dataset_column<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> methods<span class="token punctuation">:</span>
        <span class="token comment"># Before data</span>
        before_row <span class="token operator">=</span> filtered_df<span class="token punctuation">[</span>filtered_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        after_row <span class="token operator">=</span> filtered_after_df<span class="token punctuation">[</span>filtered_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> before_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            before_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>before_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset_column<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            before_data <span class="token operator">=</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> valid_data_keys<span class="token punctuation">}</span>
        
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> after_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            after_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>after_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset_column<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            after_data <span class="token operator">=</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> <span class="token number">0</span> <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> valid_data_keys<span class="token punctuation">}</span>
        
        <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> valid_data_keys<span class="token punctuation">:</span>
            <span class="token keyword keyword-if">if</span> <span class="token punctuation">(</span>method<span class="token punctuation">,</span> dataset_column<span class="token punctuation">,</span> key<span class="token punctuation">)</span> <span class="token keyword keyword-not">not</span> <span class="token keyword keyword-in">in</span> aggregated_data<span class="token punctuation">:</span>
                aggregated_data<span class="token punctuation">[</span><span class="token punctuation">(</span>method<span class="token punctuation">,</span> dataset_column<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
                    <span class="token string">'before'</span><span class="token punctuation">:</span> before_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">'after'</span><span class="token punctuation">:</span> after_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
                <span class="token punctuation">}</span>

<span class="token comment"># Aggregating data for all datasets</span>
<span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    aggregate_data_for_dataset<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>

<span class="token comment"># Convert the aggregated data to a DataFrame</span>
heatmap_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">.</span>from_dict<span class="token punctuation">(</span>aggregated_data<span class="token punctuation">,</span> orient<span class="token operator">=</span><span class="token string">'index'</span><span class="token punctuation">)</span>

<span class="token comment"># Normalize the data for better heatmap visualization</span>
heatmap_data_normalized <span class="token operator">=</span> <span class="token punctuation">(</span>heatmap_data <span class="token operator">-</span> heatmap_data<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>heatmap_data<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> heatmap_data<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Plotting the heatmap for 'retain' key as an example</span>
<span class="token keyword keyword-import">import</span> seaborn <span class="token keyword keyword-as">as</span> sns

retain_data <span class="token operator">=</span> heatmap_data_normalized<span class="token punctuation">.</span>xs<span class="token punctuation">(</span><span class="token string">'retain'</span><span class="token punctuation">,</span> level<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>heatmap<span class="token punctuation">(</span>retain_data<span class="token punctuation">,</span> annot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'coolwarm'</span><span class="token punctuation">,</span> cbar_kws<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'Normalized Value'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Heatmap of Retain Metric (Normalized) Across Methods and Datasets'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Data'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Method + Dataset'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre><p><img src="result_analysis_files/result_analysis_17_0.png" alt="png"></p>
<h1 id="箱线图">箱线图 </h1>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Preparing the data for box plot visualization</span>
<span class="token comment"># Extract data for box plot visualization for all methods and datasets</span>

box_plot_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment"># Function to collect data for a given method and metric</span>
<span class="token keyword keyword-def">def</span> <span class="token function">collect_box_plot_data</span><span class="token punctuation">(</span>method<span class="token punctuation">,</span> metric<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        before_row <span class="token operator">=</span> filtered_df<span class="token punctuation">[</span>filtered_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        after_row <span class="token operator">=</span> filtered_after_df<span class="token punctuation">[</span>filtered_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> before_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            before_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>before_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span>metric<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            before_data <span class="token operator">=</span> <span class="token boolean">None</span>
        
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> after_row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            after_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>after_row<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span>metric<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            after_data <span class="token operator">=</span> <span class="token boolean">None</span>
        
        box_plot_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>method<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> <span class="token string">'Before'</span><span class="token punctuation">,</span> before_data<span class="token punctuation">)</span><span class="token punctuation">)</span>
        box_plot_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>method<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> <span class="token string">'After'</span><span class="token punctuation">,</span> after_data<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Collecting data for the 'retain' metric as an example</span>
metric <span class="token operator">=</span> <span class="token string">'retain'</span>
<span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> methods<span class="token punctuation">:</span>
    collect_box_plot_data<span class="token punctuation">(</span>method<span class="token punctuation">,</span> metric<span class="token punctuation">)</span>

<span class="token comment"># Convert the collected data to a DataFrame</span>
box_plot_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>box_plot_data<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">,</span> <span class="token string">'Dataset'</span><span class="token punctuation">,</span> <span class="token string">'Time'</span><span class="token punctuation">,</span> <span class="token string">'Value'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Plotting the box plot for 'retain' metric</span>
plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>data<span class="token operator">=</span>box_plot_df<span class="token punctuation">,</span> x<span class="token operator">=</span><span class="token string">'Dataset'</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'Value'</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token string">'Time'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Box Plot of Retain Metric Across Methods and Datasets'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Dataset + Model'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Retain Metric'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre><p><img src="result_analysis_files/result_analysis_19_0.png" alt="png"></p>
<h1 id="其他图">其他图 </h1>
<h2 id="粗略">粗略 </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> seaborn <span class="token keyword keyword-as">as</span> sns
<span class="token keyword keyword-from">from</span> pandas<span class="token punctuation">.</span>plotting <span class="token keyword keyword-import">import</span> scatter_matrix
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np
<span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword keyword-import">import</span> StandardScaler
<span class="token keyword keyword-from">from</span> mpl_toolkits<span class="token punctuation">.</span>mplot3d <span class="token keyword keyword-import">import</span> Axes3D
<span class="token keyword keyword-import">import</span> networkx <span class="token keyword keyword-as">as</span> nx

<span class="token comment"># Prepare the data for visualization</span>
<span class="token keyword keyword-def">def</span> <span class="token function">prepare_data</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> dataset_column<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row <span class="token keyword keyword-in">in</span> df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        method <span class="token operator">=</span> row<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        json_data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset_column<span class="token punctuation">]</span><span class="token punctuation">)</span>
        json_data<span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span> <span class="token operator">=</span> method
        data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>json_data<span class="token punctuation">)</span>
    <span class="token keyword keyword-return">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment"># Preparing data for 'ft_before' and 'ft_after' for a specific dataset</span>
dataset_column <span class="token operator">=</span> <span class="token string">'cifar10_resnet18'</span>
before_data <span class="token operator">=</span> prepare_data<span class="token punctuation">(</span>filtered_df<span class="token punctuation">,</span> dataset_column<span class="token punctuation">)</span>
after_data <span class="token operator">=</span> prepare_data<span class="token punctuation">(</span>filtered_after_df<span class="token punctuation">,</span> dataset_column<span class="token punctuation">)</span>

<span class="token comment"># Standardizing the data for parallel coordinates plot</span>
scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
before_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>before_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
after_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>after_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

before_scaled_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>before_scaled<span class="token punctuation">,</span> columns<span class="token operator">=</span>before_data<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
after_scaled_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>after_scaled<span class="token punctuation">,</span> columns<span class="token operator">=</span>after_data<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
before_scaled_df<span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span> <span class="token operator">=</span> before_data<span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span>
after_scaled_df<span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span> <span class="token operator">=</span> after_data<span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span>


plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># Parallel Coordinates Plot</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pd<span class="token punctuation">.</span>plotting<span class="token punctuation">.</span>parallel_coordinates<span class="token punctuation">(</span>before_scaled_df<span class="token punctuation">,</span> <span class="token string">'Method'</span><span class="token punctuation">,</span> color<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Set1<span class="token punctuation">.</span>colors<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>
pd<span class="token punctuation">.</span>plotting<span class="token punctuation">.</span>parallel_coordinates<span class="token punctuation">(</span>after_scaled_df<span class="token punctuation">,</span> <span class="token string">'Method'</span><span class="token punctuation">,</span> color<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Set2<span class="token punctuation">.</span>colors<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Parallel Coordinates Plot for cifar10_resnet18 (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Metrics'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Standardized Values'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Before'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'After'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># Violin Plot</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>violinplot<span class="token punctuation">(</span>data<span class="token operator">=</span><span class="token punctuation">[</span>before_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> after_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Violin Plot for cifar10_resnet18 (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Metrics'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Values'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>before_data<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> before_data<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># Scatter Matrix Plot</span>
combined_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>before_data<span class="token punctuation">,</span> after_data<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
combined_data<span class="token punctuation">[</span><span class="token string">'Type'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Before'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>before_data<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'After'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>after_data<span class="token punctuation">)</span>
scatter_matrix<span class="token punctuation">(</span>combined_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">,</span> <span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> diagonal<span class="token operator">=</span><span class="token string">'kde'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string">'Scatter Matrix Plot for cifar10_resnet18 (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># 3D Scatter Plot</span>
fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">,</span> projection<span class="token operator">=</span><span class="token string">'3d'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>before_data<span class="token punctuation">[</span><span class="token string">'retain'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> before_data<span class="token punctuation">[</span><span class="token string">'forget'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> before_data<span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Before'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>after_data<span class="token punctuation">[</span><span class="token string">'retain'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> after_data<span class="token punctuation">[</span><span class="token string">'forget'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> after_data<span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'After'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Retain'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Forget'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_zlabel<span class="token punctuation">(</span><span class="token string">'Val'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'3D Scatter Plot for cifar10_resnet18 (Before vs. After)'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># Network Graph (Example using a similarity matrix approach)</span>
G <span class="token operator">=</span> nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Add nodes with a attribute "type" as before or after</span>
<span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row <span class="token keyword keyword-in">in</span> before_data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    G<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'before_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> attr_dict<span class="token operator">=</span>row<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row <span class="token keyword keyword-in">in</span> after_data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    G<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'after_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> attr_dict<span class="token operator">=</span>row<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Create edges based on some similarity measure, here using simple Euclidean distance threshold</span>
threshold <span class="token operator">=</span> <span class="token number">15</span>  <span class="token comment"># Example threshold value</span>
<span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row1 <span class="token keyword keyword-in">in</span> before_data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-for">for</span> j<span class="token punctuation">,</span> row2 <span class="token keyword keyword-in">in</span> after_data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        distance <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>row1<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'Method'</span><span class="token punctuation">)</span> <span class="token operator">-</span> row2<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">'Method'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> distance <span class="token operator">&lt;</span> threshold<span class="token punctuation">:</span>
            G<span class="token punctuation">.</span>add_edge<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'before_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'after_</span><span class="token interpolation"><span class="token punctuation">{</span>j<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> weight<span class="token operator">=</span>distance<span class="token punctuation">)</span>

pos <span class="token operator">=</span> nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> with_labels<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> node_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span> edge_color<span class="token operator">=</span><span class="token string">'grey'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Network Graph for cifar10_resnet18 (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


</code></pre><pre class="language-text">/tmp/ipykernel_240749/2993118787.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  method = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_22_1.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_22_2.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_22_3.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_22_4.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_22_5.png" alt="png"></p>
<h2 id="详细">详细 </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Complex Visualizations for Multiple Scenarios</span>

<span class="token comment"># Re-prepare data for visualization</span>
<span class="token keyword keyword-def">def</span> <span class="token function">re_prepare_data</span><span class="token punctuation">(</span>filtered_df<span class="token punctuation">)</span><span class="token punctuation">:</span>
    all_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            data_row <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">)</span>
            data_row<span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">]</span> <span class="token operator">=</span> row<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            data_row<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span> <span class="token operator">=</span> dataset
            all_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data_row<span class="token punctuation">)</span>
    <span class="token keyword keyword-return">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>all_data<span class="token punctuation">)</span>

<span class="token comment"># Preparing data for 'ft_before' and 'ft_after' for all datasets</span>
before_data_all <span class="token operator">=</span> re_prepare_data<span class="token punctuation">(</span>filtered_df<span class="token punctuation">)</span>
after_data_all <span class="token operator">=</span> re_prepare_data<span class="token punctuation">(</span>filtered_after_df<span class="token punctuation">)</span>

<span class="token comment"># Parallel Coordinates Plot with more details</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> before_data_all<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    before_dataset_data <span class="token operator">=</span> before_data_all<span class="token punctuation">[</span>before_data_all<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span> <span class="token operator">==</span> dataset<span class="token punctuation">]</span>
    after_dataset_data <span class="token operator">=</span> after_data_all<span class="token punctuation">[</span>after_data_all<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span> <span class="token operator">==</span> dataset<span class="token punctuation">]</span>
    
    pd<span class="token punctuation">.</span>plotting<span class="token punctuation">.</span>parallel_coordinates<span class="token punctuation">(</span>before_dataset_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'Method'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">)</span>
    pd<span class="token punctuation">.</span>plotting<span class="token punctuation">.</span>parallel_coordinates<span class="token punctuation">(</span>after_dataset_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'Method'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Parallel Coordinates Plot for Multiple Datasets (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Metrics'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Standardized Values'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Before'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'After'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># Violin Plot with more details</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
combined_data_all <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>before_data_all<span class="token punctuation">.</span>assign<span class="token punctuation">(</span>Type<span class="token operator">=</span><span class="token string">'Before'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> after_data_all<span class="token punctuation">.</span>assign<span class="token punctuation">(</span>Type<span class="token operator">=</span><span class="token string">'After'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>violinplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'Dataset'</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'retain'</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token string">'Type'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>combined_data_all<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Violin Plot for Multiple Datasets (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Dataset'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Retain'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># Scatter Matrix Plot with more details</span>
scatter_matrix<span class="token punctuation">(</span>combined_data_all<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">,</span> <span class="token string">'Dataset'</span><span class="token punctuation">,</span> <span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">,</span> diagonal<span class="token operator">=</span><span class="token string">'kde'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string">'Scatter Matrix Plot for Multiple Datasets (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>

<span class="token comment"># 3D Scatter Plot with more datasets and details</span>
fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">,</span> projection<span class="token operator">=</span><span class="token string">'3d'</span><span class="token punctuation">)</span>
<span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> before_data_all<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    before_dataset_data <span class="token operator">=</span> before_data_all<span class="token punctuation">[</span>before_data_all<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span> <span class="token operator">==</span> dataset<span class="token punctuation">]</span>
    after_dataset_data <span class="token operator">=</span> after_data_all<span class="token punctuation">[</span>after_data_all<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span> <span class="token operator">==</span> dataset<span class="token punctuation">]</span>

    ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>before_dataset_data<span class="token punctuation">[</span><span class="token string">'retain'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> before_dataset_data<span class="token punctuation">[</span><span class="token string">'forget'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> before_dataset_data<span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>dataset<span class="token punctuation">}</span></span><span class="token string"> Before'</span></span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>after_dataset_data<span class="token punctuation">[</span><span class="token string">'retain'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> after_dataset_data<span class="token punctuation">[</span><span class="token string">'forget'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> after_dataset_data<span class="token punctuation">[</span><span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>dataset<span class="token punctuation">}</span></span><span class="token string"> After'</span></span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>

ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Retain'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Forget'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_zlabel<span class="token punctuation">(</span><span class="token string">'Val'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'3D Scatter Plot for Multiple Datasets (Before vs. After)'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


</code></pre><pre class="language-text">/tmp/ipykernel_240749/636374906.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  data_row['Method'] = row[0]
</pre>
<p><img src="result_analysis_files/result_analysis_24_1.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_24_2.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_24_3.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_24_4.png" alt="png"></p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Re-attempt the Network Graph with correct data handling</span>
G <span class="token operator">=</span> nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Adding nodes and edges with combined data</span>
<span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row <span class="token keyword keyword-in">in</span> combined_data_all<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    G<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>row<span class="token punctuation">[</span><span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>row<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> <span class="token operator">**</span>row<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Calculate distance and add edges</span>
<span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> row1 <span class="token keyword keyword-in">in</span> combined_data_all<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-for">for</span> j<span class="token punctuation">,</span> row2 <span class="token keyword keyword-in">in</span> combined_data_all<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-if">if</span> row1<span class="token punctuation">[</span><span class="token string">'Type'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> row2<span class="token punctuation">[</span><span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>row1<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">,</span> <span class="token string">'Dataset'</span><span class="token punctuation">,</span> <span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            data2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>row2<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Method'</span><span class="token punctuation">,</span> <span class="token string">'Dataset'</span><span class="token punctuation">,</span> <span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            distance <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>data1 <span class="token operator">-</span> data2<span class="token punctuation">)</span>  <span class="token comment"># Correct usage of np.linalg.norm</span>
            <span class="token keyword keyword-if">if</span> distance <span class="token operator">&lt;</span> threshold<span class="token punctuation">:</span>
                G<span class="token punctuation">.</span>add_edge<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>row1<span class="token punctuation">[</span><span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>row1<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>row2<span class="token punctuation">[</span><span class="token string">'Type'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>row2<span class="token punctuation">[</span><span class="token string">'Dataset'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>j<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> weight<span class="token operator">=</span>distance<span class="token punctuation">)</span>

pos <span class="token operator">=</span> nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> with_labels<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> node_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span> edge_color<span class="token operator">=</span><span class="token string">'grey'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Complex Network Graph for Multiple Datasets (Before vs. After)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre><p><img src="result_analysis_files/result_analysis_25_0.png" alt="png"></p>
<h1 id="test">TEST </h1>
<h2 id="雷达图---unlearn-acc">雷达图 - Unlearn ACC </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> pandas <span class="token keyword keyword-as">as</span> pd
<span class="token keyword keyword-import">import</span> json
<span class="token keyword keyword-import">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword keyword-as">as</span> plt
<span class="token keyword keyword-import">import</span> os
<span class="token keyword keyword-import">import</span> zipfile
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np

<span class="token comment"># # Step 1: Unzip the files</span>
<span class="token comment"># ft_before_extract_path = '/mnt/data/ft_before_corrected'</span>
<span class="token comment"># ft_after_extract_path = '/mnt/data/ft_after_corrected'</span>

<span class="token comment"># with zipfile.ZipFile('/mnt/data/ft_before.zip', 'r') as zip_ref:</span>
<span class="token comment">#     zip_ref.extractall(ft_before_extract_path)</span>

<span class="token comment"># with zipfile.ZipFile('/mnt/data/ft_after.zip', 'r') as zip_ref:</span>
<span class="token comment">#     zip_ref.extractall(ft_after_extract_path)</span>

<span class="token comment"># # Step 2: Define the paths for 'unlearn_acc.csv' files</span>

<span class="token comment"># ft_before_correct_path = os.path.join(ft_before_extract_path, 'ft_before', 'unlearn_acc.csv')</span>
<span class="token comment"># ft_after_correct_path = os.path.join(ft_after_extract_path, 'ft_after', 'unlearn_acc.csv')</span>

ft_before_correct_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_before'</span><span class="token punctuation">,</span> <span class="token string">'unlearn_acc.csv'</span><span class="token punctuation">)</span>
ft_after_correct_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_after'</span><span class="token punctuation">,</span> <span class="token string">'unlearn_acc.csv'</span><span class="token punctuation">)</span>

<span class="token comment"># Step 3: Load the CSV files into DataFrames</span>
unlearn_acc_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>ft_before_correct_path<span class="token punctuation">)</span>
unlearn_acc_after_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>ft_after_correct_path<span class="token punctuation">)</span>

<span class="token comment"># Step 4: Correct the JSON format in the DataFrames</span>
<span class="token keyword keyword-def">def</span> <span class="token function">correct_json_format</span><span class="token punctuation">(</span>json_str<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-return">return</span> json_str<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">'"'</span><span class="token punctuation">)</span>

unlearn_acc_df_corrected <span class="token operator">=</span> unlearn_acc_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
unlearn_acc_after_df_corrected <span class="token operator">=</span> unlearn_acc_after_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> unlearn_acc_df_corrected<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    unlearn_acc_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> unlearn_acc_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>
    unlearn_acc_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> unlearn_acc_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>

<span class="token comment"># Step 5: Filter out rows with non-dictionary JSON data</span>
<span class="token keyword keyword-def">def</span> <span class="token function">is_valid_json</span><span class="token punctuation">(</span>val<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-try">try</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>val<span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-except">except</span> <span class="token punctuation">(</span>json<span class="token punctuation">.</span>JSONDecodeError<span class="token punctuation">,</span> TypeError<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> <span class="token boolean">False</span>

filtered_df <span class="token operator">=</span> unlearn_acc_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
filtered_after_df <span class="token operator">=</span> unlearn_acc_after_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> col <span class="token keyword keyword-in">in</span> filtered_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    filtered_df <span class="token operator">=</span> filtered_df<span class="token punctuation">[</span>filtered_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>
    filtered_after_df <span class="token operator">=</span> filtered_after_df<span class="token punctuation">[</span>filtered_after_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token comment"># Step 6: Extract the valid data keys</span>
first_valid_data_cell <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>filtered_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
valid_data_keys <span class="token operator">=</span> first_valid_data_cell<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-def">def</span> <span class="token function">plot_radar_chart_comparison</span><span class="token punctuation">(</span>before_data<span class="token punctuation">,</span> after_data<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> dataset_title<span class="token punctuation">,</span> methods<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_vars <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    angles <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> num_vars<span class="token punctuation">,</span> endpoint<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    before_data <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>before_data<span class="token punctuation">,</span> before_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    after_data <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>after_data<span class="token punctuation">,</span> after_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    angles <span class="token operator">+=</span> angles<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>

    plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>
    fig<span class="token punctuation">,</span> axs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> subplot_kw<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>polar<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    axs <span class="token operator">=</span> axs<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
    fig<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Radar Chart Comparison for </span><span class="token interpolation"><span class="token punctuation">{</span>dataset_title<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token number">1.03</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-for">for</span> i<span class="token punctuation">,</span> method <span class="token keyword keyword-in">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>methods<span class="token punctuation">)</span><span class="token punctuation">:</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>angles<span class="token punctuation">,</span> before_data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Before'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>fill<span class="token punctuation">(</span>angles<span class="token punctuation">,</span> before_data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>angles<span class="token punctuation">,</span> after_data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'After'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>fill<span class="token punctuation">(</span>angles<span class="token punctuation">,</span> after_data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span>

        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>set_theta_offset<span class="token punctuation">(</span>np<span class="token punctuation">.</span>pi <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>set_theta_direction<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span>angles<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>set_yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>set_yticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'0.2'</span><span class="token punctuation">,</span> <span class="token string">'0.4'</span><span class="token punctuation">,</span> <span class="token string">'0.6'</span><span class="token punctuation">,</span> <span class="token string">'0.8'</span><span class="token punctuation">,</span> <span class="token string">'1.0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"grey"</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>method<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        axs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">,</span> bbox_to_anchor<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'default'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>rect<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.95</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figtext<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token string">'Blue represents "Before" and Red represents "After". Each chart represents a different unlearning method.'</span><span class="token punctuation">,</span> ha<span class="token operator">=</span><span class="token string">'center'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

methods <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'retrain'</span><span class="token punctuation">,</span> <span class="token string">'FT'</span><span class="token punctuation">,</span> <span class="token string">'FF'</span><span class="token punctuation">,</span> <span class="token string">'GA'</span><span class="token punctuation">,</span> <span class="token string">'IU'</span><span class="token punctuation">,</span> <span class="token string">'FT_prune'</span><span class="token punctuation">]</span>

<span class="token comment"># Process and plot for each dataset and model combination</span>
<span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> datasets<span class="token punctuation">:</span>
    <span class="token comment"># Get data for ft_before</span>
    before_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> methods<span class="token punctuation">:</span>
        method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        row <span class="token operator">=</span> filtered_df<span class="token punctuation">[</span>filtered_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            before_data_json <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span>before_data_json<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> valid_data_keys<span class="token punctuation">]</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_data_keys<span class="token punctuation">)</span>
        before_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>method_data<span class="token punctuation">)</span>
    
    <span class="token comment"># Get data for ft_after</span>
    after_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> methods<span class="token punctuation">:</span>
        method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        row <span class="token operator">=</span> filtered_after_df<span class="token punctuation">[</span>filtered_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            after_data_json <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span>after_data_json<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> valid_data_keys<span class="token punctuation">]</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_data_keys<span class="token punctuation">)</span>
        after_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>method_data<span class="token punctuation">)</span>
    
    <span class="token comment"># Plot radar charts for ft_before and ft_after</span>
    plot_radar_chart_comparison<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>before_data<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>after_data<span class="token punctuation">)</span><span class="token punctuation">,</span> valid_data_keys<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> methods<span class="token punctuation">)</span>

</code></pre><p><img src="result_analysis_files/result_analysis_29_0.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_29_1.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_29_2.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_29_3.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_29_4.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_29_5.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_29_6.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_29_7.png" alt="png"></p>
<h2 id="雷达图---mia">雷达图 - MIA </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># Define the paths for 'mia_after.csv' files</span>
mia_before_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_before'</span><span class="token punctuation">,</span> <span class="token string">'mia_after.csv'</span><span class="token punctuation">)</span>
mia_after_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'ft_after'</span><span class="token punctuation">,</span> <span class="token string">'mia_after.csv'</span><span class="token punctuation">)</span>

<span class="token comment"># Load the CSV files into DataFrames</span>
mia_before_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>mia_before_path<span class="token punctuation">)</span>
mia_after_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>mia_after_path<span class="token punctuation">)</span>

<span class="token comment"># Correct the JSON format in the DataFrames</span>
mia_before_df_corrected <span class="token operator">=</span> mia_before_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
mia_after_df_corrected <span class="token operator">=</span> mia_after_df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> mia_before_df_corrected<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    mia_before_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> mia_before_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>
    mia_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> mia_after_df_corrected<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>correct_json_format<span class="token punctuation">)</span>

<span class="token comment"># Filter out rows with non-dictionary JSON data</span>
filtered_mia_before_df <span class="token operator">=</span> mia_before_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
filtered_mia_after_df <span class="token operator">=</span> mia_after_df_corrected<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-for">for</span> col <span class="token keyword keyword-in">in</span> filtered_mia_before_df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    filtered_mia_before_df <span class="token operator">=</span> filtered_mia_before_df<span class="token punctuation">[</span>filtered_mia_before_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>
    filtered_mia_after_df <span class="token operator">=</span> filtered_mia_after_df<span class="token punctuation">[</span>filtered_mia_after_df<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>is_valid_json<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token comment"># Extract the valid data keys</span>
first_valid_mia_data_cell <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>filtered_mia_before_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
valid_mia_data_keys <span class="token operator">=</span> first_valid_mia_data_cell<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Process and plot for each dataset and model combination</span>
<span class="token keyword keyword-for">for</span> dataset <span class="token keyword keyword-in">in</span> datasets<span class="token punctuation">:</span>
    <span class="token comment"># Get data for ft_before</span>
    mia_before_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> methods<span class="token punctuation">:</span>
        method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        row <span class="token operator">=</span> filtered_mia_before_df<span class="token punctuation">[</span>filtered_mia_before_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            mia_before_data_json <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span>mia_before_data_json<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> valid_mia_data_keys<span class="token punctuation">]</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_mia_data_keys<span class="token punctuation">)</span>
        mia_before_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>method_data<span class="token punctuation">)</span>
    
    <span class="token comment"># Get data for ft_after</span>
    mia_after_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword keyword-for">for</span> method <span class="token keyword keyword-in">in</span> methods<span class="token punctuation">:</span>
        method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        row <span class="token operator">=</span> filtered_mia_after_df<span class="token punctuation">[</span>filtered_mia_after_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> method<span class="token punctuation">]</span>
        <span class="token keyword keyword-if">if</span> <span class="token keyword keyword-not">not</span> row<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
            mia_after_data_json <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>row<span class="token punctuation">[</span>dataset<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span>mia_after_data_json<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> key <span class="token keyword keyword-in">in</span> valid_mia_data_keys<span class="token punctuation">]</span>
        <span class="token keyword keyword-else">else</span><span class="token punctuation">:</span>
            method_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_mia_data_keys<span class="token punctuation">)</span>
        mia_after_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>method_data<span class="token punctuation">)</span>
    
    <span class="token comment"># Plot radar charts for mia_after data</span>
    plot_radar_chart_comparison<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>mia_before_data<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>mia_after_data<span class="token punctuation">)</span><span class="token punctuation">,</span> valid_mia_data_keys<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> methods<span class="token punctuation">)</span>

</code></pre><p><img src="result_analysis_files/result_analysis_31_0.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_31_1.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_31_2.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_31_3.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_31_4.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_31_5.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_31_6.png" alt="png"></p>
<p><img src="result_analysis_files/result_analysis_31_7.png" alt="png"></p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>